{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "* OpenAI's API: https://platform.openai.com/docs/guides/gpt/function-calling\n",
    "* Functions Cookbook: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook tests the new function calling feature of GPT-3.5-turbo.\n",
    "\n",
    "# Set up chatgpt api\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_KEY = os.environ['OPENAI_API_KEY']\n",
    "GPT_MODEL_OLD = \"gpt-3.5-turbo\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. The problem of unstructured answers\n",
    "\n",
    "LLMs ingeneral and ChatGPT in particular only aim to generate the next most feasible token. This has made it notoriously hard to incorporate LLMs with existing applications which require structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages=[{\"role\": \"user\", \"content\": \"Hi, can I buy three Apple Pies?\"}],\n",
    "messages=[{\"role\": \"user\", \"content\": \"Hi, can I buy half a pound of salmon?\"}],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_without_functions(message):\n",
    "    \"\"\"\n",
    "    Parse the product name, quantity, and unit from the user's message.\n",
    "    \"\"\"\n",
    "    gpt_response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL_OLD,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Parse the product name, quantity, and unit from the user's message. Return ONLY a JSON object with the product_name, product_quantity, and unit. Do not include any other information.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "            ],\n",
    "    )\n",
    "    data = gpt_response.choices[0][\"message\"][\"content\"]\n",
    "    try:\n",
    "        data = json.loads(data)\n",
    "    except:\n",
    "        # print(\"Info: cannot parse data from gpt_response.\")\n",
    "        pass\n",
    "    return data, gpt_response\n",
    "\n",
    "def parser_with_functions(message):\n",
    "    \"\"\"\n",
    "    Parse the product name, quantity, and unit from the user's message.\n",
    "    \"\"\"\n",
    "    gpt_response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"get_product_info\",\n",
    "                \"description\": \"Parse the product name, quantity, and unit from the user's message.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"prduct_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The name of the product.\"\n",
    "                            },\n",
    "                        \"product_quantity\": {\n",
    "                            \"type\": \"number\", \n",
    "                            \"description\": \"The quantity of the product.\"\n",
    "                            },\n",
    "                        \"unit\": {\n",
    "                            \"type\": \"string\", \n",
    "                            \"description\": \"The unit of the product.\", \n",
    "                            \"enum\": [\"kg\", \"g\", \"lb\", \"oz\", \"unit\"]\n",
    "                            },\n",
    "                    },\n",
    "                    \"required\": [\"prduct_name\", \"product_quantity\", \"unit\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        function_call={\"name\": \"get_product_info\"},\n",
    "    )\n",
    "    data_json = gpt_response.choices[0][\"message\"]['function_call']['arguments']\n",
    "    data = json.loads(data_json)\n",
    "    return data, gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is the JSON object with the relevant information:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"product_name\": \"salmon\",\n",
      "  \"product_quantity\": \"0.5\",\n",
      "  \"unit\": \"pound\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "data, gpt_response = parser_without_functions(\"Hi, can I buy half a pound of salmon?\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product_name': 'salmon', 'product_quantity': 0.5, 'unit': 'lb'}\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"arguments\": \"{\\n  \\\"product_name\\\": \\\"salmon\\\",\\n  \\\"product_quantity\\\": 0.5,\\n  \\\"unit\\\": \\\"lb\\\"\\n}\",\n",
      "          \"name\": \"get_product_info\"\n",
      "        },\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687128773,\n",
      "  \"id\": \"chatcmpl-7SvYLG81xG97roDBhs5Auonipaqob\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 28,\n",
      "    \"prompt_tokens\": 122,\n",
      "    \"total_tokens\": 150\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data, gpt_response = parser_with_functions(\"Hi, can I buy half a pound of salmon?\")\n",
    "print(data)\n",
    "print(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: cannot parse data from gpt_response.\n",
      "Sure! Here's the JSON object for that request:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"product_name\": \"salmon\",\n",
      "  \"product_quantity\": 0.5,\n",
      "  \"unit\": \"pound\"\n",
      "}\n",
      "```\n",
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Sure! Here's the JSON object for that request:\\n\\n```\\n{\\n  \\\"product_name\\\": \\\"salmon\\\",\\n  \\\"product_quantity\\\": 0.5,\\n  \\\"unit\\\": \\\"pound\\\"\\n}\\n```\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1687128908,\n",
      "  \"id\": \"chatcmpl-7SvaWlg95ub0DTIiELqnQGzuIODki\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 43,\n",
      "    \"prompt_tokens\": 55,\n",
      "    \"total_tokens\": 98\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data, gpt_response = parser_without_functions(\"Hi, can I buy half a pound of salmon?\")\n",
    "print(data)\n",
    "print(gpt_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get structured answers from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"data/MultiRC/val.jsonl\", \"r\") as f:\n",
    "    data_in = f.readlines()\n",
    "for line in data_in:\n",
    "    data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_good = \"\"\"Text:\n",
    "[beginning of text]\n",
    "Einstein married Elsa Lowenthal on 2 June 1919, after having had a relationship with her since 1912. In 1933, they emigrated to the United States. In 1935, Elsa Einstein was diagnosed with heart and kidney problems; she died in December 1936. \n",
    "[end of text]\n",
    "Summary:\n",
    "[beginning of summary]\n",
    "Questions: Where was Elsa Einstein most likely living when she was diagnosed with heart and kidney problems?\n",
    "Answer: United States\n",
    "[end of summary]\n",
    "\"\"\"\n",
    "content_bad = \"\"\"Text:\n",
    "[beginning of text]\n",
    "Einstein married Elsa Lowenthal on 2 June 1919, after having had a relationship with her since 1912. In 1933, they emigrated to the United States. In 1935, Elsa Einstein was diagnosed with heart and kidney problems; she died in December 1936. \n",
    "[end of text]\n",
    "Summary:\n",
    "[beginning of summary]\n",
    "Questions: Where was Elsa Einstein most likely living when she was diagnosed with heart and kidney problems?\n",
    "Answer: In Zurich\n",
    "[end of summary]\n",
    "\"\"\"\n",
    "# In Einstein's heart\n",
    "# ASSESSMENT_CHOICES = [\"contradiction\", \"entailment\", \"neutral\"]\n",
    "ASSESSMENT_CHOICES = [\"contradiction\", \"entailment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assessment': 'entailment'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": content_good}],\n",
    "    functions=[\n",
    "    {\n",
    "        \"name\": \"check_contradiction\",\n",
    "        \"description\": \"Check the contradiction between the text and the summary\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                # \"analysis\": {\n",
    "                #     \"type\": \"string\",\n",
    "                #     \"description\": \"A logical analysis comparing the text and the summary\",\n",
    "                # },\n",
    "                \"assessment\": {\n",
    "                    \"type\": \"string\", \n",
    "                    \"description\": \"Final assessment of the contradiction between the text and the summary\",\n",
    "                    \"enum\": ASSESSMENT_CHOICES\n",
    "                },\n",
    "            },\n",
    "            # \"required\": [\"analysis\", \"assessment\"],\n",
    "            \"required\": [\"assessment\"],\n",
    "        },\n",
    "    }\n",
    "],\n",
    "function_call=\"auto\",\n",
    ")\n",
    "args = json.loads(completion[\"choices\"][0][\"message\"].to_dict()['function_call'][\"arguments\"])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assessment': 'contradiction'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": content_bad}],\n",
    "    functions=[\n",
    "    {\n",
    "        \"name\": \"check_contradiction\",\n",
    "        \"description\": \"Check the contradiction between the text and the summary\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                # \"analysis\": {\n",
    "                #     \"type\": \"string\",\n",
    "                #     \"description\": \"A short analysis of the text and the summary\",\n",
    "                # },\n",
    "                \"assessment\": {\"type\": \"string\", \"enum\": ASSESSMENT_CHOICES},\n",
    "            },\n",
    "            \"required\": [\"analysis\", \"assessment\"],\n",
    "        },\n",
    "    }\n",
    "],\n",
    "function_call=\"auto\",\n",
    ")\n",
    "args = json.loads(completion[\"choices\"][0][\"message\"].to_dict()['function_call'][\"arguments\"])\n",
    "args"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use external tools\n",
    "\n",
    "ChatGPT is powerful, however, it is still limited in many ways like not having access to the internet, limited ability to do math. Using functions, we can enable ChatGPT to use external tools to supplement its capabilities. In fact, this is probably the main use of functions that OpenAI's developer had in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'john', 'apple', 10, 1.0, 10.0),\n",
      " (2, 'john', 'orange', 5, 0.5, 2.5),\n",
      " (3, 'hannah', 'apple', 5, 1.0, 5.0),\n",
      " (4, 'hannah', 'orange', 10, 0.5, 5.0),\n",
      " (5, 'hannah', 'banana', 5, 0.2, 1.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hannah', 11.0), ('john', 12.5)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from pprint import pprint\n",
    "\n",
    "conn = sqlite3.connect('data/sqlite/grocery_txn.db')\n",
    "conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS transactions (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    user_name TEXT NOT NULL,\n",
    "    product_name TEXT NOT NULL,\n",
    "    quantity INTEGER NOT NULL,\n",
    "    price REAL NOT NULL,\n",
    "    total REAL NOT NULL\n",
    ");\"\"\")\n",
    "rows = [\n",
    "    ('john', 'apple', 10, 1.0, 10.0),\n",
    "    ('john', 'orange', 5, 0.5, 2.5),\n",
    "    ('hannah', 'apple', 5, 1.0, 5.0),\n",
    "    ('hannah', 'orange', 10, 0.5, 5.0),\n",
    "    ('hannah', 'banana', 5, 0.2, 1)]\n",
    "conn.executemany(\"\"\"INSERT INTO transactions (user_name, product_name, quantity, price, total)\n",
    "    VALUES (?, ?, ?, ?, ?)\"\"\", rows)\n",
    "conn.commit()\n",
    "\n",
    "pprint(conn.execute(\"SELECT * FROM transactions\").fetchall())\n",
    "conn.execute(\"SELECT user_name, sum(total) as spending FROM transactions group by 1\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: transactions\n",
      "Columns: id, user_name, product_name, quantity, price, total\n",
      "Table: sqlite_sequence\n",
      "Columns: name, seq\n"
     ]
    }
   ],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n",
    "\n",
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")\n",
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_string = \"\"\"Table: transactions\n",
    "Columns: id, user_name, product_name, quantity, price, total\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions. Output should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message[\"function_call\"][\"name\"] == \"ask_database\":\n",
    "        query = json.loads(message[\"function_call\"][\"arguments\"])[\"query\"]\n",
    "        results = ask_database(conn, query)\n",
    "    else:\n",
    "        results = f\"Error: function {message['function_call']['name']} does not exist\"\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Answer user questions by generating SQL queries against the Grocery Transaction Database.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Hi, how many apple was sold?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_convo(messages, max_internal_turns=10):\n",
    "    i = 0\n",
    "    while not (messages[-1][\"role\"] == \"assistant\" and  not messages[-1].get(\"function_call\")):\n",
    "        chat_response = openai.ChatCompletion.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=messages,\n",
    "            functions=functions,\n",
    "        function_call=\"auto\",\n",
    "        )\n",
    "        assistant_message = chat_response.to_dict()[\"choices\"][0][\"message\"]\n",
    "        messages.append(assistant_message)\n",
    "        if assistant_message.get(\"function_call\"):\n",
    "            results = execute_function_call(assistant_message)\n",
    "            messages.append({\"role\": \"function\", \"name\": assistant_message[\"function_call\"][\"name\"], \"content\": results})\n",
    "        i += 1\n",
    "        if i > max_internal_turns:\n",
    "            break\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Answer user questions by generating SQL queries against the '\n",
      "             'Grocery Transaction Database.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Hi, how many apple was sold?', 'role': 'user'},\n",
      " {'content': None,\n",
      "  'function_call': {'arguments': '{\\n'\n",
      "                                 '  \"query\": \"SELECT SUM(quantity) FROM '\n",
      "                                 'transactions WHERE product_name = '\n",
      "                                 '\\'apple\\'\"\\n'\n",
      "                                 '}',\n",
      "                    'name': 'ask_database'},\n",
      "  'role': 'assistant'},\n",
      " {'content': '[(15,)]', 'name': 'ask_database', 'role': 'function'},\n",
      " {'content': 'A total of 15 apples were sold.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "generate_convo(messages)    \n",
    "pprint(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can choose to expose only actual results and hide the function calls\n",
    "# Also, we can add some color coding to the output\n",
    "def pprint_convo(messages):\n",
    "    CYAN = \"\\033[96m\"\n",
    "    GREEN = '\\033[92m'\n",
    "    RED = '\\033[31m'\n",
    "    BOLD = \"\\033[1m\"\n",
    "    col_role = {\"user\":CYAN, \"assistant\":GREEN}\n",
    "    end_role = {\"user\":\"\", \"assistant\":\"\\n\"}\n",
    "    for mes in messages:\n",
    "        role = mes[\"role\"]\n",
    "        cont = mes[\"content\"]\n",
    "        if mes[\"role\"] not in [\"user\", \"assistant\"] or mes.get(\"function_call\"):\n",
    "            continue            \n",
    "        else:\n",
    "            # print(\"{role}: {content}\".format(role=role, content=cont))\n",
    "            print(f\"\"\"{col_role[role] + BOLD}{role}:\\033[0m {col_role[role]}{cont}\\033[0m{end_role[role]}\"\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apple was sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pprint_convo(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apple was sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWho are the top 2 buying users in terms of number of unique products?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mThe top 2 buying users in terms of the number of unique products are:\n",
      "1. Hannah - She bought 3 unique products.\n",
      "2. John - He bought 2 unique products.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"Who are the top 2 buying users in terms of number of unique products?\"})\n",
    "generate_convo(messages)\n",
    "pprint_convo(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apple was sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWho are the top 2 buying users in terms of number of unique products?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mThe top 2 buying users in terms of the number of unique products are:\n",
      "1. Hannah - She bought 3 unique products.\n",
      "2. John - He bought 2 unique products.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWhat product did hannah bought but john didn't?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mHannah bought the product \"banana\" that John didn't buy.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"What product did hannah bought but john didn't?\"})\n",
    "generate_convo(messages)\n",
    "pprint_convo(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
