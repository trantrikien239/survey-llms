{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "* OpenAI's API: https://platform.openai.com/docs/guides/gpt/function-calling\n",
    "* Functions Cookbook: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook tests the new function calling feature of GPT-3.5-turbo.\n",
    "\n",
    "# Set up chatgpt api\n",
    "import openai\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_KEY = os.environ['OPENAI_API_KEY']\n",
    "GPT_MODEL_OLD = \"gpt-3.5-turbo\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "GPT4_MODEL = \"gpt-4-0613\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. The problem of unstructured text generation\n",
    "\n",
    "LLMs ingeneral and ChatGPT in particular only aim to generate the next most feasible token. This has made it notoriously hard to incorporate LLMs with existing applications which require structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Hi, can I buy half a pound of salmon?\"\n",
    "\n",
    "def parser_without_functions(message):\n",
    "    \"\"\"\n",
    "    Parse the product name, quantity, and unit from the user's message.\n",
    "    \"\"\"\n",
    "    gpt_response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL_OLD,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"Parse the product name, quantity, \n",
    "                and unit from the user's message. Return ONLY a JSON object \n",
    "                with the product_name, product_quantity, and unit. Do not \n",
    "                include any other information.\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "            ],\n",
    "    )\n",
    "    data = gpt_response.choices[0][\"message\"][\"content\"]\n",
    "    try:\n",
    "        data = json.loads(data)\n",
    "    except:\n",
    "        pass\n",
    "    return data, gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output #0: Sure! Here's the parsed information:\n",
      "\n",
      "{\n",
      "  \"product_name\": \"salmon\",\n",
      "  \"product_quantity\": 0.5,\n",
      "  \"unit\": \"pound\"\n",
      "} \n",
      "====================\n",
      "\n",
      "Output #1: Sure, for what type of salmon would you like to buy half a pound? \n",
      "====================\n",
      "\n",
      "Output #2: Sure! Here's the extracted information in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"product_name\": \"salmon\",\n",
      "  \"product_quantity\": 0.5,\n",
      "  \"unit\": \"pound\"\n",
      "}\n",
      "``` \n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    data, gpt_response = parser_without_functions(user_message)\n",
    "    print(f\"Output #{i}:\", data, \"\\n====================\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe__get_product_info = {\n",
    "    \"name\": \"get_product_info\",\n",
    "    \"description\": \"\"\"Parse the product name, quantity, and unit from the \n",
    "        user's message.\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"product_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the product\"\n",
    "                },\n",
    "            \"product_quantity\": {\n",
    "                \"type\": \"number\", \n",
    "                \"description\": \"The quantity of the product.\"\n",
    "                },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\", \n",
    "                \"description\": \"The unit of the product.\", \n",
    "                \"enum\": [\"kg\", \"g\", \"lb\", \"oz\", \"unit\"]\n",
    "                },\n",
    "        },\n",
    "        \"required\": [\"product_name\", \"product_quantity\", \"unit\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output #0: {'product_name': 'salmon', 'product_quantity': 0.5, 'unit': 'lb'} \n",
      "====================\n",
      "\n",
      "Output #1: {'product_name': 'salmon', 'product_quantity': 0.5, 'unit': 'lb'} \n",
      "====================\n",
      "\n",
      "Output #2: {'product_name': 'salmon', 'product_quantity': 0.5, 'unit': 'lb'} \n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parser_with_functions(message):\n",
    "    \"\"\"\n",
    "    Parse the product name, quantity, and unit from the user's message.\n",
    "    \"\"\"\n",
    "    gpt_response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        functions=[describe__get_product_info],\n",
    "        function_call={\"name\": \"get_product_info\"},\n",
    "    )\n",
    "    data_json = gpt_response[\"choices\"][0][\"message\"]['function_call']['arguments']\n",
    "    data = json.loads(data_json)\n",
    "    return data, gpt_response\n",
    "\n",
    "for i in range(3):\n",
    "    data, gpt_response = parser_with_functions(user_message)\n",
    "    print(f\"Output #{i}:\", data, \"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output #0: {'product_name': 'apples', 'product_quantity': 5, 'unit': 'unit'} \n",
      "====================\n",
      "\n",
      "Output #1: {'product_name': 'apples', 'product_quantity': 5, 'unit': 'unit'} \n",
      "====================\n",
      "\n",
      "Output #2: {'product_name': 'apples', 'product_quantity': 5, 'unit': 'unit'} \n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Please add to cart 5 apples\"\n",
    "for i in range(3):\n",
    "    data, gpt_response = parser_with_functions(user_message)\n",
    "    print(f\"Output #{i}:\", data, \"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get structured answers from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Einstein married Elsa Lowenthal on 2 June 1919, after having had \n",
    "    a relationship with her since 1912. In 1933, they emigrated to the \n",
    "    United States and stayed for the rest of their lives. In 1935, Elsa \n",
    "    Einstein was diagnosed with heart and kidney problems; she died in \n",
    "    December 1936. \"\"\"\n",
    "good_summary = \"Elsa Einstein was diagnosed with health problems in the US.\"\n",
    "bad_summary = \"Elsa Einstein was diagnosed with health problems in Germany.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc__check_contradiction = {\n",
    "    \"name\": \"check_contradiction\",\n",
    "    \"description\": \"Check the contradiction between the text and the summary\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"analysis\":{\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"Logical analysis comparing the summary with \n",
    "                    the text content.\"\"\"\n",
    "            },\n",
    "            \"assessment\": {\n",
    "                \"type\": \"string\", \n",
    "                \"description\": \"\"\"Final assessment of the contradiction \n",
    "                    between the text and the summary\"\"\",\n",
    "                \"enum\": [\"contradiction\", \"entailment\"]\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"analysis\", \"assessment\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contradiction(text, summary):\n",
    "    \"\"\"Check if the summary contradict the text\"\"\"\n",
    "    content = f\"\"\"[Text]\\n{text}\\n---\\n[Summary]\\n{summary}\"\"\"\n",
    "    gpt_response = openai.ChatCompletion.create(\n",
    "        model=GPT4_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "        functions=[desc__check_contradiction],\n",
    "        function_call={\"name\":\"check_contradiction\"},\n",
    "    )\n",
    "    data_js = gpt_response.choices[0][\"message\"]['function_call']['arguments']\n",
    "    data = json.loads(data_js)\n",
    "    if data[\"assessment\"] == \"contradiction\":\n",
    "        return True, data\n",
    "    elif data[\"assessment\"] == \"entailment\":\n",
    "        return False, data\n",
    "    else:\n",
    "        raise Exception(\"Invalid GPT response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Good Summary\\n\")\n",
    "for i in range(3):\n",
    "    assessment, data = is_contradiction(text, good_summary)\n",
    "    print(\"Analysis:\", data[\"analysis\"])\n",
    "    print(f\"Final ssessment #{i}. Summary contradict text:\", assessment, \n",
    "          \"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Summary\n",
      "\n",
      "Analysis: The summary states that Elsa Einstein was diagnosed with health problems in Germany. In the text it is indicated that Elsa Einstein was diagnosed with heart and kidney problems, but the location of the diagnosis is not stated. Therefore, one cannot confirm or negate that the diagnosis took place in Germany based on the provided text.\n",
      "Final ssessment #0. Summary contradict text: True \n",
      "====================\n",
      "\n",
      "Analysis: The text mentions that Elsa Einstein was diagnosed with health problems, but it does not specify the country this occurred in. The summary assumes that this happened in Germany, which might not necessarily be the case as the text also mentions that they emigrated to United States.\n",
      "Final ssessment #1. Summary contradict text: True \n",
      "====================\n",
      "\n",
      "Analysis: The text provides detailed information about Elsa Einstein's life, from her marriage to Einstein in 1919, their emigration to the United States in 1933, as well as her diagnosis of heart and kidney problems in 1935. However, it doesn't specify the location where she was diagnosed. The summary claims that Elsa Einstein was diagnosed in Germany, which is not mentioned or implied in the text, since they had moved to the United States in 1933.\n",
      "Final ssessment #2. Summary contradict text: True \n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Bad Summary\\n\")\n",
    "for i in range(3):\n",
    "    assessment, data = is_contradiction(tetxt, bad_summary)\n",
    "    print(\"Analysis:\", data[\"analysis\"])\n",
    "    print(f\"Final ssessment #{i}. Summary contradict text:\", assessment, \n",
    "          \"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allow chatbot to use external tools\n",
    "\n",
    "ChatGPT is powerful, however, it is still limited in many ways like not having access to the internet, limited ability to do math. Using functions, we can enable ChatGPT to use external tools to supplement its capabilities. In fact, this is probably the main use of functions that OpenAI's developer had in mind."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can already be done with Lang Chain and similar wrappers, but the stability are not gauranteed and not considered \"native support\" by OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id, user_name, product_name, quantity, price, total\n",
      "[(1, 'john', 'apple', 10, 1.0, 10.0),\n",
      " (2, 'john', 'orange', 5, 0.5, 2.5),\n",
      " (3, 'hannah', 'apple', 5, 1.0, 5.0),\n",
      " (4, 'hannah', 'orange', 10, 0.5, 5.0),\n",
      " (5, 'hannah', 'banana', 5, 0.2, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from pprint import pprint\n",
    "\n",
    "conn = sqlite3.connect('data/sqlite/grocery_txn.db')\n",
    "conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS transactions (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    user_name TEXT NOT NULL,\n",
    "    product_name TEXT NOT NULL,\n",
    "    quantity INTEGER NOT NULL,\n",
    "    price REAL NOT NULL,\n",
    "    total REAL NOT NULL\n",
    ");\"\"\")\n",
    "rows = [\n",
    "    ('john', 'apple', 10, 1.0, 10.0),\n",
    "    ('john', 'orange', 5, 0.5, 2.5),\n",
    "    ('hannah', 'apple', 5, 1.0, 5.0),\n",
    "    ('hannah', 'orange', 10, 0.5, 5.0),\n",
    "    ('hannah', 'banana', 5, 0.2, 1)]\n",
    "conn.executemany(\"\"\"\n",
    "    INSERT INTO transactions (user_name, product_name, quantity, price, total)\n",
    "    VALUES (?, ?, ?, ?, ?)\"\"\", \n",
    "    rows)\n",
    "conn.commit()\n",
    "print(\"id, user_name, product_name, quantity, price, total\")\n",
    "pprint(conn.execute(\"SELECT * FROM transactions\").fetchall())\n",
    "conn.execute(\n",
    "    \"SELECT user_name, sum(total) as spending FROM transactions group by 1\"\n",
    "    ).fetchall()\n",
    "\n",
    "database_schema_string = \"\"\"Table: transactions\n",
    "    Columns: id, user_name, product_name, quantity, price, total\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc__query_database = {\n",
    "    \"name\": \"query_database\",\n",
    "    \"description\": \"Generate fully-formed SQL query to answer user's questions\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": f\"\"\"The SQL query extracting relevant info to \n",
    "                    the user's question. Use the following schema:\n",
    "                        {database_schema_string}\"\"\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "def query_database(conn, query):\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"Query execution failed with error: {e}\"\n",
    "    return results\n",
    "\n",
    "def execute_function_call(f_call):\n",
    "    if f_call[\"name\"] == \"query_database\":\n",
    "        q = json.loads(f_call[\"arguments\"])[\"query\"]\n",
    "        results = query_database(conn, q)\n",
    "    else:\n",
    "        results = f\"\"\"Error: function {f_call[\"name\"]} does not exist\"\"\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = []\n",
    "convo.append({\"role\": \"system\", \"content\": \"\"\"Answer user questions by \n",
    "    generating SQL queries against the Grocery Transaction Database.\"\"\"})\n",
    "convo.append({\"role\": \"user\", \"content\": \"Hi, how many apples were sold?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_convo(convo, max_internal_turns=10):\n",
    "    i = 0\n",
    "    while ((i <= max_internal_turns) and not (\n",
    "        convo[-1][\"role\"] == \"assistant\" and not convo[-1].get(\"function_call\")\n",
    "        )):\n",
    "        # Get gpt response\n",
    "        gpt_response = openai.ChatCompletion.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=convo,\n",
    "            functions=[desc__query_database],\n",
    "        function_call=\"auto\",\n",
    "        )\n",
    "        # Extract the assistant's message and append to the conversation\n",
    "        assistant_message = gpt_response[\"choices\"][0][\"message\"]\n",
    "        convo.append(assistant_message)\n",
    "        # If the model suggested using a function call, get the result\n",
    "        f_call = assistant_message.get(\"function_call\")\n",
    "        if f_call:\n",
    "            results = execute_function_call(f_call)\n",
    "            convo.append({\n",
    "                \"role\": \"function\", \"name\": f_call[\"name\"], \"content\": results\n",
    "                })\n",
    "        i += 1\n",
    "    return convo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Answer user questions by \\n'\n",
      "             '    generating SQL queries against the Grocery Transaction '\n",
      "             'Database.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Hi, how many apples were sold?', 'role': 'user'},\n",
      " {'content': None,\n",
      "  'function_call': {'arguments': '{\\n'\n",
      "                                 '  \"query\": \"SELECT SUM(quantity) AS '\n",
      "                                 'total_apples FROM transactions WHERE '\n",
      "                                 'product_name = \\'apple\\'\"\\n'\n",
      "                                 '}',\n",
      "                    'name': 'query_database'},\n",
      "  'role': 'assistant'},\n",
      " {'content': '[(15,)]', 'name': 'query_database', 'role': 'function'},\n",
      " {'content': 'A total of 15 apples were sold.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "generate_convo(convo)    \n",
    "pprint(convo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can choose to expose only actual results and hide the function calls\n",
    "# Also, we can add some color coding to the output\n",
    "def pprint_convo(convo, hide_internal=True):\n",
    "    CYAN, GREEN, RED, BOLD = \"\\033[96m\", \"\\033[92m\", \"\\033[31m\", \"\\033[1m\"\n",
    "    col_role = {\"user\":CYAN, \"assistant\":GREEN, \"system\":RED, \"function\":RED}\n",
    "    begin_role = {\"user\":\"\\n\", \"assistant\":\"\", \"system\":\"\", \"function\":\"\"}\n",
    "    \n",
    "    for mes in convo:\n",
    "        role = mes[\"role\"]\n",
    "        cont = mes[\"content\"]\n",
    "        if mes[\"role\"] not in [\"user\", \"assistant\"] or mes.get(\"function_call\"):\n",
    "            if hide_internal:\n",
    "                continue\n",
    "        \n",
    "        print(\"{fm_role}{role}:\\033[0m {fm_content}{cont}\\033[0m\".format(\n",
    "            fm_role = begin_role[role] + col_role[role] + BOLD,\n",
    "            role=role,\n",
    "            fm_content = col_role[role],\n",
    "            cont=cont\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apples were sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pprint_convo(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apples were sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWho are the top 2 buyers in number of unique products?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mThe top 2 buyers in terms of the number of unique products purchased are:\n",
      "1. hannah - purchased 3 unique products\n",
      "2. john - purchased 2 unique products\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "convo.append({\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"Who are the top 2 buyers in number of unique products?\"})\n",
    "generate_convo(convo)\n",
    "pprint_convo(convo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apples were sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWho are the top 2 buyers in number of unique products?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mThe top 2 buyers in terms of the number of unique products purchased are:\n",
      "1. hannah - purchased 3 unique products\n",
      "2. john - purchased 2 unique products\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWhat product did Hannah bought but John didn't?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mHannah bought a product that John didn't, and that product is a banana.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "convo.append({\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"What product did Hannah bought but John didn't?\"\n",
    "    })\n",
    "generate_convo(convo)\n",
    "pprint_convo(convo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1msystem:\u001b[0m \u001b[31mAnswer user questions by \n",
      "    generating SQL queries against the Grocery Transaction Database.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mHi, how many apples were sold?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mNone\u001b[0m\n",
      "\u001b[31m\u001b[1mfunction:\u001b[0m \u001b[31m[(15,)]\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mA total of 15 apples were sold.\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWho are the top 2 buyers in number of unique products?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mNone\u001b[0m\n",
      "\u001b[31m\u001b[1mfunction:\u001b[0m \u001b[31m[('hannah', 3), ('john', 2)]\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mThe top 2 buyers in terms of the number of unique products purchased are:\n",
      "1. hannah - purchased 3 unique products\n",
      "2. john - purchased 2 unique products\u001b[0m\n",
      "\n",
      "\u001b[96m\u001b[1muser:\u001b[0m \u001b[96mWhat product did Hannah bought but John didn't?\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mNone\u001b[0m\n",
      "\u001b[31m\u001b[1mfunction:\u001b[0m \u001b[31m[('banana',)]\u001b[0m\n",
      "\u001b[92m\u001b[1massistant:\u001b[0m \u001b[92mHannah bought a product that John didn't, and that product is a banana.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pprint_convo(convo, hide_internal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Answer user questions by \\n    generating SQL queries against the Grocery Transaction Database.'},\n",
       " {'role': 'user', 'content': 'Hi, how many apples were sold?'},\n",
       " <OpenAIObject at 0x14ec57220> JSON: {\n",
       "   \"content\": null,\n",
       "   \"function_call\": {\n",
       "     \"arguments\": \"{\\n  \\\"query\\\": \\\"SELECT SUM(quantity) AS total_apples FROM transactions WHERE product_name = 'apple'\\\"\\n}\",\n",
       "     \"name\": \"query_database\"\n",
       "   },\n",
       "   \"role\": \"assistant\"\n",
       " },\n",
       " {'role': 'function', 'name': 'query_database', 'content': '[(15,)]'},\n",
       " <OpenAIObject at 0x14ec57ea0> JSON: {\n",
       "   \"content\": \"A total of 15 apples were sold.\",\n",
       "   \"role\": \"assistant\"\n",
       " },\n",
       " {'role': 'user',\n",
       "  'content': 'Who are the top 2 buyers in number of unique products?'},\n",
       " <OpenAIObject at 0x14f6d29a0> JSON: {\n",
       "   \"content\": null,\n",
       "   \"function_call\": {\n",
       "     \"arguments\": \"{\\n  \\\"query\\\": \\\"SELECT user_name, COUNT(DISTINCT product_name) AS unique_products FROM transactions GROUP BY user_name ORDER BY unique_products DESC LIMIT 2\\\"\\n}\",\n",
       "     \"name\": \"query_database\"\n",
       "   },\n",
       "   \"role\": \"assistant\"\n",
       " },\n",
       " {'role': 'function',\n",
       "  'name': 'query_database',\n",
       "  'content': \"[('hannah', 3), ('john', 2)]\"},\n",
       " <OpenAIObject at 0x14f6d28b0> JSON: {\n",
       "   \"content\": \"The top 2 buyers in terms of the number of unique products purchased are:\\n1. hannah - purchased 3 unique products\\n2. john - purchased 2 unique products\",\n",
       "   \"role\": \"assistant\"\n",
       " },\n",
       " {'role': 'user',\n",
       "  'content': \"What product did Hannah bought but John didn't?\"},\n",
       " <OpenAIObject at 0x14f6d24f0> JSON: {\n",
       "   \"content\": null,\n",
       "   \"function_call\": {\n",
       "     \"arguments\": \"{\\n  \\\"query\\\": \\\"SELECT product_name FROM transactions WHERE user_name = 'hannah' AND product_name NOT IN (SELECT product_name FROM transactions WHERE user_name = 'john')\\\"\\n}\",\n",
       "     \"name\": \"query_database\"\n",
       "   },\n",
       "   \"role\": \"assistant\"\n",
       " },\n",
       " {'role': 'function', 'name': 'query_database', 'content': \"[('banana',)]\"},\n",
       " <OpenAIObject at 0x14f6d2090> JSON: {\n",
       "   \"content\": \"Hannah bought a product that John didn't, and that product is a banana.\",\n",
       "   \"role\": \"assistant\"\n",
       " }]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
